\documentclass[12pt,a4paper]{article}
\usepackage[legalpaper, portrait, margin=3cm]{geometry}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{biblatex}

\graphicspath{ {./} }
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  filecolor=magenta,
  urlcolor=blue,
  citecolor=blue,
  pdftitle={Relatório IA - Projeto - 2021/2022},
  pdfpagemode=FullScreen,
}
\addbibresource{./bibliography.bib}

\pagestyle{fancy}
\fancyhf{}
\rhead{Grupo \textbf{al002}}
\lhead{Relatório Projeto IA 2021/2022 LEIC-A}
\cfoot{Diogo Melita (99202) e Tomás Esteves (99341)}

\renewcommand{\footrulewidth}{0.2pt}

\renewcommand{\labelitemii}{$\circ$}
\renewcommand{\labelitemiii}{$\diamond$}

\begin{document}
  \section{Descrição do Problema e Implementação}

  Foi pedido para desenvolver um programa em Python que resolve o problema Takuzu utilizando técnicas de procura de IA.
  Começou-se por implementar as regras do jogo:

  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \item Há um número igual de 1s e 0s em cada linha e coluna (ou mais um para grelhas de
    dimensão ímpar).
    \item Não há mais do que dois números iguais adjacentes (horizontal ou verticalmente) um ao
    outro.
    \item Todas as linhas são diferentes.
    \item Todas as colunas são diferentes.
  \end{itemize}

  Depois de implementadas as regras rapidamente percebeu-se que o tempo de execução do programa aumentava exponencialmente com o tamanho do tabuleiro (posições livres).
  Sendo o Takuzu conhecido também por Sudoku Binário inferiu-se que existem posições livres que podem ser ocupadas por uma peça dado um estado do tabuleiro. 
  Alguns dos casos implementados foram:
  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \item Se houver 2 casas de seguida com o mesmo valor, as posições adjacentes em linha têm de ter obrigatoriamente ter o valor contrário a essas 2 casas.
    \item Se num tabuleiro par(ímpar) uma linha/coluna tiver metade(metade + 1) dos valores preenchidos com um valor, sabemos obrigatoriamente que as outras casas vazias têm de ser do valor contrário. 
  \end{itemize}

  Mesmo com estas impelementações nem todos os tabuleiros se resolviam.
  Para isso foi implementado um CSP onde primeiro tenta encontrar posições livres que apenas aceitam um valor.
  No caso de não encontrar é atribuído um valor à primeira casa livre.
  Se mais à frente no algoritmo, uma posição não tiver valores possíveis, volta-se para trás e escolhe-se o outro valor para a variável.

  Isto permite assim resolver eficientemente tabuleiros de Takuzu com tamanhos grandes($>$ 30)
  

  \section{Análise Teórica}

  Para comparar algoritmos vamos usar como critérios, o tempo de execução, o número de nós expandidos e o número de nós gerados.
  Para saber o tempo de execução foi feita a média de pelo menos 5 testes para cada input, recorrendo ao programa \href{https://github.com/sharkdp/hyperfine}{\textit{hyperfine}}.
  Para saber o número de nós expandidos e o número de nós gerados foi usado código encontrado em search.py.

  // TODO add data

  
  Todas as procuras garantem completude, apesar de umas serem mais eficientes que outras, isto deve-se a no caso de haver solução podem sempre testar todos as combinações de tabuleiro possíveis e chegar ao objetivo.
  Apesar de um puzzle de Takuzu poder ter mais do que 1 solução possível, todas as soluções encontram-se sempre todas ao mesmo nível que equivale ao número inicial de posições livres, sendo assim não é importante falar da otimilidade do algoritmo.
  
  A heurística usada consiste em relacionar o número de posições livres e a linha em que a ação está a ser feita.
  Dado a maneira como foi desenvolvido o algoritmo, quando é necessário fazer uma escolha entre os dois valores, é escolhido a primeira
  posição livre,
  Como se vizualiza o tabuleiro da esquerda para a direita e de cima para baixo, uma escolha numa linha mais abaixo significa que o resto das posições livres se encontram mais concentradas, logo havendo maior probabilidade de o puzzle acabar mais rápido.
  Assim temos que
  $$
  h(n) = {num\_de\_pos\_lives} - \frac{1}{num\_actions} * (size\_board - 1 - num_row_of_action)
  $$

  Temos que um tabuleiro com menos número de posições livres é superior a um que tenha mais.
  Considera-se que numa posição livre onde podem ocorrer as 2 ações vai ser pior que numa onde apenas pode acontecer 1 ação.
  Assim saber onde a ação foi feita tem menos importância quando apenas há 1 ação. 
  
  Esta heurística apenas melhora a perfomance do algoritmo, não melhorando a sua otimilidade. 

  Temos ainda que $h*(n) = num\_pos_livres$, logo podemos conluir que esta heurística não é admissível.



  Seja $N$ o número de elementos da sequência 1 e $M$ o número de elementos da sequência 2.

  \subsection{Problema 1}

  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \item Simples leitura do input, colocando cada elemento num vetor. Logo, $\Theta(N)$.
    \item Criação de uma lista vazia de stacks é feito em tempo constante, logo $\Theta(1)$.
    \item Cada elemento da sequência é visitado uma vez, logo $\Theta(N)$.
    \begin{itemize}
      \setlength{\itemsep}{0pt}
      \item A lista de pilhas encontra-se ordenada pelo elemento no topo da pilha, pelo que se pode aplicar o algoritmo \textit{binary search} para determinar em que pilha inserir o elemento. Logo, $O(\log N)$.
      \item Cada pilha encontra-se também ordenada, pelo que se pode determinar o índice do maior elemento menor que o elemento a inserir também pelo algoritmo \textit{binary search}. Determinar o elemento no topo da pilha é feito em tempo constante. Logo, $O(\log N)$.
      \item Obter o elemento no topo da pilha é feito em tempo constante, logo a soma à quantidade é $\Theta(1)$.
      \item Adicionar um elemento à pilha é feito também em tempo constante. Logo, $\Theta(1)$.
      \item Finalmente, adicionar uma pilha à lista é também em tempo constante. Logo, $\Theta(1)$.
    \end{itemize}
    \item A obtenção das soluções após construir a lista de pilhas, assim como a aprensen-tação dos resultados, são feitas em tempo constante. Logo, $\Theta(1)$.
  \end{itemize}

  Assim, a complexidade global da solução do problema 1 é $O(N \log N)$.

  No problema 1, tem-se complexidade espacial $\Theta(N)$, visto que cada elemento da sequência é adicionado à lista de pilhas uma e apenas uma só vez.

  \subsection{Problema 2}

  No problema 2, efetua-se um pré-processamento na leitura do input:
    Para a sequência 1 coloca-se cada elemento num vetor e num hashset.
    Para a sequência 2 apenas se coloca os elementos num vetor que se encontram no hashset da sequência 1, isto é, apenas os números em comum nas duas sequências.
  No pior caso, a inserção e leitura do hashset tem complexidade $O(N)$.
  No entanto, o caso médio é $O(1)$.
  Logo, no pior caso tem-se $O(N^2 + NM)$, mas no caso médio tem-se $O(N + M)$.

  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \item Criação de um vetor de tamanho $M$ é feito em tempo linear, logo $\Theta(M)$.
    \item Cada elemento de sequência 1 é visitado uma vez, logo $\Theta(N)$.
    \begin{itemize}
      \setlength{\itemsep}{0pt}
      \item Cada elemento da sequência 2 é visitado no máximo uma vez (para cada elemento da sequência 1). Relembra-se que alguns elementos foram retirados no pré-processamento do \textit{input}. Logo, $O(M)$.
      \begin{itemize}
        \setlength{\itemsep}{0pt}
        \item São efetuadas comparações entre o elemento da sequência 1 e sequência 2, atualizando no máximo um valor do vetor. Logo, $\Theta(1)$.
      \end{itemize}
    \end{itemize}
  \end{itemize}

  Assim, a complexidade global da solução do problema 2 é, no pior caso $O(N^2 + NM)$, mas no caso médio é $O(NM)$.

  No problema 2, tem-se complexidade espacial $O(N + M)$, visto que se utilizou um hashset com tamanho máximo igual ao da primeira sequência no pré-processamento do input e um vetor auxiliar na resolução do problema com tamanho máximo inferior ao da sequência 2 (devido ao pré-processamento do \textit{input}).

  \section{Avaliação Experimental dos Resultados}

  O programa foi executado, pelo menos 5 vezes para cada sequência, para ambos os problemas, recorrendo ao programa \href{https://github.com/sharkdp/hyperfine}{\textit{hyperfine}}.

  \begin{wrapfigure}{r}{0.4\textwidth}
    \centering
    \includegraphics[width=0.4\textwidth]{report_prob1.png}
    \includegraphics[width=0.4\textwidth]{report_prob2.png}
  \end{wrapfigure}

  Para o problema 1, foram utilizadas sequências de tamanho entre 10 e 100 000 000 elementos, 100 para cada ordem de grandeza.
  O gráfico apresentado à direita tem uma escala $N \log N$ no eixo dos $xx$.
  Os dados revelam uma reta linear, comprovando que a complexidade temporal do problema é efetivamente $O(N\log N)$, tal como concluido na análise teórica.

  Para o problema 2, por ser o pior caso e para simplificar a análise, tomou-se sempre $N = M$, ou seja, o mesmo número de elementos para ambas as sequências.
  Foram sempre utilizados números comuns, visto que esse é o pior caso no problema 2.
  Foram utilizadas sequências de tamanho entre 10 e 100 000 elementos, 100 para cada ordem de grandeza.
  O gráfico apresentado à direta tem uma escala $NM$ no eixo dos $xx$.
  Os dados revelam uma reta linear, comprovando que a complexidade temporal do problema é, num caso geral, $O(NM)$, tal como concluído na análise teórica.

  \section{Bibliografia}

  \printbibliography

\end{document}